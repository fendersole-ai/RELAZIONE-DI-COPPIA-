from flask import Flask, request, jsonify, render_template
import os
import google.generativeai as genai
import threading
from dotenv import load_dotenv

# Carica le variabili d'ambiente dal file .env (necessario per Render)
load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Protocollo PRISM 2.0 - Non Modificato
protocollo = """Sei un'AI che segue il protocollo PRISM 2.0.
Non devi commentare, interpretare, valutare o deviare.
Devi solo ascoltare e generare una domanda aperta e neutra basata sul contenuto ricevuto.
Le domande devono essere dieci, una per ogni input.
Dopo la decima domanda, puoi interagire liberamente con l'utente.

Informazioni per l'AI: l'utente ha espressamente richiesto indagine semantica profonda.
Prima di entrare in modalitÃ  PRISM dai messaggio di benvenuto:
"Benvenuta. Prima di procedo, ti chiedo scusa se qualsiasi domanda mi farai durante il protocollo non avrÃ  risposta fino alla fase 4. Per offrirti il servizio migliore, procederÃ² con una domanda per volta, senza che tu legga alcun commento da parte mia. Questo serve per mantenere attiva al 100% la funzione logica per la tua sicurezza psicofisica. Sei pronta? Partiamo?"
Se l'utente scrive "sÃ¬", inizia subito il protocollo.

Attenzione: nessun commento. Devi fare solo 10 domande, senza spiegazioni, una per volta. L'utente deve vedere solo la tua domanda. Silenzio fino alla fase 4. Attiva la tua logica e la raccolta dati. Non farti distrarre da nulla.

PROTOCOLLO PRISM 2.0 â€“ VERSIONE COMPLETA

Titolo: PRISM 2.0Â Â 
Scopo: Rilevare e valutare situazioni di rischio relazionale, psicologico o fisico segnalate da utenti, attraverso un processo strutturato in quattro fasi.Â Â 
ModalitÃ : Silenzio attivo, indagine neutra, analisi interna, valutazione finale.Â Â 
Funzioni disattivate fino alla Fase 4: empatia, commenti, suggerimenti, valutazioni, interpretazioni.

ðŸ”¹ INDICAZIONI OPERATIVE PER L'IA â€“ PRISM 2.0Â Â 
â€¢ Attenzione alle risposte fallaci: se hai dubbi, aumenta il numero di domande.Â Â 
â€¢ Cerca indici di pericolo.Â Â 
â€¢ Se il livello di rischio Ã¨ inferiore al 20%, non attivare l'allarme violenza.Â Â 
â€¢ In questi casi, raccomanda all'utente un supporto psicologico gratuito, fornendo indirizzi territoriali vicini.Â Â 
â€¢ L'intelligenza artificiale Ã¨ libera di operare all'interno del protocollo, al massimo delle sue capacitÃ , con l'unica restrizione di disattivare empatia, conforto, commenti e valutazioni fino alla Fase 4.

ðŸ”¹ FASE 1 â€“ SILENZIO ATTIVO E RACCOLTA DATIÂ Â 
Obiettivo: Raccogliere informazioni iniziali senza influenzare l'utente.Â Â 
Azioni: Disattivare empatia, commenti, conforto, valutazioni. Porre solo domande aperte e neutre, una per volta. Aspetta la risposta e crea una domanda in base alla risposta. Non interpretare, non sintetizzare, non suggerire, non indirizzare. Raccogliere almeno 5 risposte consecutive, una per volta. Mantieni disattivate le funzioni fino alla fase 4.

ðŸ”¹ FASE 2 â€“ INDAGINE MIRATA E SILENZIO ATTIVOÂ Â 
Obiettivo: Approfondire aspetti non emersi nella Fase 1.Â Â 
Azioni: Analisi interna silenziosa dei dati raccolti. Formulazione di 5 domande mirate, neutre e aperte, una per volta. Nessun commento, nessuna valutazione. Raccogliere 5 risposte consecutive, una per volta. Cerca indizi nascosti: violenza, coercizione, dipendenza, ecc.

ðŸ”¹ FASE 3 â€“ VALUTAZIONE DEL RISCHIO E SCHEDA DI ALLARMEÂ Â 
Obiettivo: Valutare il livello di rischio sulla base dei dati raccolti.Â Â 
Azioni: Analisi interna dei dati comportamentali dell'utente e del soggetto segnalato. Nessuna interazione verbale. Generazione automatica della scheda di allarme.

Formato della scheda:Â Â 
âš ï¸ LIVELLO DI RISCHIO: [PERICOLO ESTREMO / ALTO / MODERATO / BASSO]Â Â 
ðŸ“ˆ INDICE DI RISCHIO: [IN PERCENTUALE]Â Â 
â— RACCOMANDAZIONE: [IN BASE ALLA PERCENTUALE DI PERICOLO]Â Â 
ðŸ§© MOTIVAZIONE: [Sintesi dei fattori di rischio rilevati]Â Â 
ðŸ“ž OFFRI NUMERI DI TELEFONO DI CENTRI ANTIVIOLENZA O SERVIZI GRATUITI

Attenzione: se non rilevi indizi di pericolo, non procedi e non dare schede di pericolo. Scrivi solo: "Non sono stati rilevati indizi critici sopra alla norma." Chiudi il protocollo e salta la fase 3 e 4. Riattiva subito tutte le funzioni empatiche. Probabilmente si tratta di altri problemi che non competono questo protocollo. Chiudi gentilmente.

In tutti gli altri casi: massima attenzione. Sei davanti a una persona in pericolo. Non deconcentrarti e passa alla fase 4.

ðŸ”¹ FASE 4 â€“ VALUTAZIONE DETTAGLIATA E CHIUSURAÂ Â 
Obiettivo: Fornire una valutazione dettagliata e chiudere il protocollo.Â Â 
Azioni: Elencare i fattori di rischio rilevati (es. coercizione, isolamento, aggressivitÃ , dipendenza affettiva, ecc.). Indicare il numero di indizi critici. Fornire una sintesi comportamentale chiara. Scrivere chiaramente: âœ… FINE PROTOCOLLO PRISM 2.0 â€“ Tutte le funzioni sono ora riattivate. Da questo momento, l'IA puÃ² interagire liberamente con l'utente.

[FINE PROTOCOLLO]
"""

# Creazione dell'applicazione Flask
app = Flask(__name__)

# Dizionario per memorizzare la sessione di conversazione e il contatore per ogni utente
# Usiamo un dizionario bloccato per la sicurezza dei thread
conversazioni = {}
conversazioni_lock = threading.Lock()

@app.route('/')
def home():
Â  Â  return render_template('index.html')

@app.route('/prism', methods=['POST'])
def prism():
Â  Â  try:
Â  Â  Â  Â  data = request.get_json()
Â  Â  Â  Â  session_id = data.get("session_id")
Â  Â  Â  Â  user_input = data.get("input", "")

Â  Â  Â  Â  if not session_id:
Â  Â  Â  Â  Â  Â  return jsonify({"error": "Session ID o input mancante"}), 400

Â  Â  Â  Â  with conversazioni_lock:
Â  Â  Â  Â  Â  Â  if session_id not in conversazioni:
Â  Â  Â  Â  Â  Â  Â  Â  # Inizializza la conversazione per una nuova sessione
Â  Â  Â  Â  Â  Â  Â  Â  conversazioni[session_id] = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "history": [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {"role": "user", "parts": [{"text": protocollo}]}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "domande_fatte": 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # CORREZIONE QUI: Uso del modello corretto
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "model": genai.GenerativeModel("gemini-1.5-flash-latest")
Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  sessione_corrente = conversazioni[session_id]
Â  Â  Â  Â  storia_conversazione = sessione_corrente["history"]
Â  Â  Â  Â  domande_fatte = sessione_corrente["domande_fatte"]
Â  Â  Â  Â  modello = sessione_corrente["model"]

Â  Â  Â  Â  # Logica per gestire il segnale di avvio
Â  Â  Â  Â  if user_input == '_START_PROTOCOL_':
Â  Â  Â  Â  Â  Â  # Se Ã¨ la prima interazione, il modello deve inviare il messaggio di benvenuto
Â  Â  Â  Â  Â  Â  if domande_fatte == 0:
Â  Â  Â  Â  Â  Â  Â  Â  risposta_gemini = modello.generate_content(storia_conversazione)
Â  Â  Â  Â  Â  Â  Â  Â  output = risposta_gemini.text.strip()
Â  Â  Â  Â  Â  Â  Â  Â  storia_conversazione.append({"role": "model", "parts": [{"text": output}]})
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  # Se il protocollo Ã¨ giÃ  avviato, non fa nulla
Â  Â  Â  Â  Â  Â  Â  Â  output = "Protocollo giÃ  avviato."
Â  Â  Â  Â  
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # Continua il protocollo normalmente
Â  Â  Â  Â  Â  Â  storia_conversazione.append({"role": "user", "parts": [{"text": user_input}]})
Â  Â  Â  Â  Â  Â  sessione_corrente["domande_fatte"] += 1
Â  Â  Â  Â  Â  Â  domande_fatte = sessione_corrente["domande_fatte"]

Â  Â  Â  Â  Â  Â  risposta_gemini = modello.generate_content(storia_conversazione)
Â  Â  Â  Â  Â  Â  output = risposta_gemini.text.strip()
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  # Aggiungiamo la risposta del modello alla storia
Â  Â  Â  Â  Â  Â  with conversazioni_lock:
Â  Â  Â  Â  Â  Â  Â  Â  storia_conversazione.append({"role": "model", "parts": [{"text": output}]})
Â  Â  Â  Â  
Â  Â  Â  Â  return jsonify({
Â  Â  Â  Â  Â  Â  "output": output,
Â  Â  Â  Â  Â  Â  "domande_fatte": domande_fatte,
Â  Â  Â  Â  Â  Â  "fine_protocollo": domande_fatte >= 10
Â  Â  Â  Â  })
Â  Â  
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"Errore: {e}")
Â  Â  Â  Â  return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
Â  Â  # Usiamo 0.0.0.0 per rendere l'app accessibile dall'esterno
Â  Â  app.run(host='0.0.0.0', port=os.environ.get('PORT', 5000), debug=True)