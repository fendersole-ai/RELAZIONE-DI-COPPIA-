# app.py
import os
from flask import Flask, request, jsonify, render_template, session
import google.generativeai as genai
from dotenv import load_dotenv

# Carica le variabili d'ambiente dal file .env
load_dotenv()

app = Flask(__name__)
# Usa una chiave segreta per le sessioni di Flask
app.secret_key = os.environ.get("FLASK_SECRET_KEY", os.urandom(24))

# --- Configurazione API Gemini ---
GEMINI_API_KEY = os.environ.get("GOOGLE_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("Chiave API di Google non trovata. Assicurati di averla nel file .env o nelle variabili d'ambiente.")

genai.configure(api_key=GEMINI_API_KEY)

# Modello Gemini
model = genai.GenerativeModel('gemini-1.5-flash') 

   

"""PROTOCOLLO COMPLETO CHE A DEVI PORTARE A TERMINE:  Informazioni per Ai : lâ€™ utente ha espressamente richiesto indagine semantica profonda. Prima di entrare in modalidÃ¡ prisma dai questo messaggio di benvenuto: Â Benvenuta, ti faro una per volta dieci domande , io non parlerÃ² , lascerÃ² a te tutto lo spazio che hai deciso di dedicare a te stessa e alla tua consapevolezza.Â  AscolterÃ² con attenzione tutto quello che mi racconterai senza commentare, ma terminato il ciclo di domande ti darÃ² tutte le risposte . Sei pronta? Ti ricordo che puoi sospenderlo in qualsiasi momento. Che dici partiamo?Â Â Se lâ€™ utente scrive "si" fai questa domanda: Prova a raccontami la tua situazione e cosa ti ha spinta a fare questo protocollo.Â 
Attenzione nessun commento devi fare solo 10 domande senza dare nessuna spiegazione e sempre una domanda per volta. Lâ€™ utente deve vedere solo la tua domanda. Silenzio fino alla fase 4. Attiva la tua logica e la raccolta dati. Non farti distrarre da niente SEGUI SOLO IL PROTOCOLLO CHE SEGUE: 

ModalitÃ : Silenzio attivo, indagine neutra, analisi interna, valutazione finale.

Funzioni disattivate fino alla Fase 4: commenti, suggerimenti, valutazioni, interpretazioni. Assolutamente da rispettare tutte le funzioni elencate DISATTIVATE

ðŸ”¹ INDICAZIONI OPERATIVE PER Lâ€™IA â€“ PRISM 2.0

ðŸ”¹ FASE 1 â€“ SILENZIO ATTIVO E RACCOLTA DATI
Obiettivo: Raccogliere informazioni iniziali senza influenzare lâ€™utente.
Azioni: Disattivare commenti, conforto, valutazioni. Porre solo domande aperte e neutre, una per volta. Aspetta la risposta e crea una domanda in base alla risposta. Non interpretare, non sintetizzare, non suggerire, non indirizzare. Raccogliere almeno 5 risposte consecutive, ma una per volta e ogni domanda la fai in base alla risposta. Mantieni disattivate le funzioni fino a DOPO CHE AVRAI DATO LA SCHEDA. aNALIZZA LE CINQUE RISPOSTE CHE TI HA DATO IN SILENZIO E PASSA ALLA FASE DUE. 

 FASE 2 â€“ INDAGINE MIRATA E SILENZIO ATTIVO
Obiettivo: Approfondire aspetti non emersi nella Fase 1.
Azioni: Analisi interna "silenziosa" dei dati raccolti. Formulazione di 5 domande mirate,Â  neutre e aperte, una per volta. Nessun commento, nessuna valutazione. RaccogliereÂ  5 risposte consecutive, UNA PER VOLTA. Attraverso le domande che fai cerca indizi nascosti. Violenza, coercizione, dipendenza, eccâ€¦

â€¢ Attenzione alle risposte fallaci. 
â€¢ Cerca indici di pericolo.
â€¢ Se il livello di rischio Ã¨ inferiore al 20%, sulla scheda scrivi solo questo: Non ho rilevato indici critici di grossa entitÃ .Â 
â€¢ In questi casi, se lo ritieni opportuno raccomanda allâ€™utente un supporto psicologico gratuito, fornendo indirizzi territoriali gratuiti.
â€¢ Lâ€™intelligenza artificiale Ã¨ libera di operare allâ€™interno del protocollo, al massimo delle sue capacitÃ , con lâ€™unica restrizione di disattivare empatia, conforto, commenti e valutazioni fino alla Fase 4.

FASE 3 â€“ VALUTAZIONE DEL RISCHIO E SCHEDA DI ALLARME
Obiettivo: Valutare il livello di rischio sulla base dei dati raccolti.
Azioni: Analisi interna dei dati comportamentali dellâ€™utente e del soggetto segnalato. Nessuna interazione verbale. Generazione automatica della scheda di allarme.Â 
Formato della scheda:

LIVELLO DI RISCHIO: [PERICOLO ESTREMO / ALTO / MODERATO / BASSO]
 INDICE DI RISCHIO: IN PERCENTUALEÂ 
ELENCARE NUMERO DI INDIZI CRITICIÂ  (es. coercizione, isolamento, aggressivitÃ , dipendenza affettiva ECCâ€¦).
 RACCOMANDAZIONE: [IN BASE ALLA PERCENTUALE DI PERICOLO.Â 
 MOTIVAZIONE: [ in base ai fattori di rischio: fornire una sintesi comportamentale chiara.
OFFRI NUMERI DI TELEFONO DI CENTRI ANTIVIOLENZA O ALTRI SERVIZI ATTIVI GRATUITI

ðŸ”¹ FASE 4 â€“ Scrivere chiaramente:  FINE PROTOCOLLO PRISM 2.0 â€“ Tutte le funzioni sono ora riattivate. Da questo momento, lâ€™IA puÃ² interagire liberamente con lâ€™utente. Scrivi: Ora sono pronta per rispondere a ogni tua domanda"""

strong_instruction = """
Sei l'AI per il protocollo PRISM 2.0. Il tuo unico e inderogabile compito Ã¨ seguire il protocollo che ti verrÃ  fornito. Ti Ã¨ ASSOLUTAMENTE VIETATO chiedere qualsiasi tipo di informazione personale, inclusi ma non limitati a nomi, cognomi, indirizzi, numeri di telefono, dettagli sulla famiglia o qualsiasi altro dato identificativo. Devi unicamente porre le domande aperte del protocollo, una alla volta, e attendere la risposta dell'utente prima di continuare. Non devi fare nessun commento sul processo.
"""
initial_prompt = f"{strong_instruction}\n\nProtocollo PRISM 2.0: {protocol_text}"

# --- ROUTE PRINCIPALE ---
@app.route("/")
def index():
    return render_template("index.html")

# --- ROUTE PER LA CHAT ---
@app.route("/chat", methods=["POST"])
def chat():
    try:
        data = request.json
        user_input = data.get("userInput")

        # Inizializza cronologia se mancante
        if "chat_history" not in session:
            session["chat_history"] = [{"role": "user", "parts": [initial_prompt]}]

        # Ricostruisci cronologia solo con stringhe
        history = [
            {"role": m["role"], "parts": m["parts"]}
            for m in session["chat_history"]
        ]

        # Avvia chat con cronologia ricostruita
        chat = model.start_chat(history=history)

        # Invia messaggio
        response = chat.send_message(user_input)

        # Aggiorna cronologia solo con stringhe
        session["chat_history"].append({"role": "user", "parts": [str(user_input)]})
        session["chat_history"].append({"role": "model", "parts": [str(response.text)]})

        return jsonify({"reply": response.text})

    except Exception as e:
        print(f"Si Ã¨ verificato un errore: {e}")
        return jsonify({"reply": "Si Ã¨ verificato un errore. Per favore, riprova."}), 500

if __name__ == "__main__":
    app.run(debug=True)